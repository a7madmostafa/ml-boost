{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "balanced-gather",
   "metadata": {},
   "source": [
    "## UGL - Normal Equations \n",
    "\n",
    "In the lecture videos, you learned that the closed-form solution to linear regression is\n",
    "\n",
    "\\begin{equation*}\n",
    "w = (X^TX)^{-1}X^Ty\n",
    "\\end{equation*}\n",
    "\n",
    "Using this formula does not require any feature scaling, and you will get an exact solution in one calculation: there is no “loop until convergence” like in gradient descent.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Complete the code in the `normal_equation()` function below to use the formula above to calculate $w$. Remember that while you don’t need to scale your features, we still need to add a column of 1’s to the original X matrix to have an intercept term $w_0$. You can assume that this has already been done in the previous parts and the variable that you should use is `X_train`.\n",
    "\n",
    "**Hint**\n",
    "Look into np.linalg.inv(), .T and np.dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Originally was the assignment dataset. Either reuse or add new one\n",
    "X_train = np.zeros((5,2)) \n",
    "y_train = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y): \n",
    "    \"\"\"\n",
    "    Computes the closed-form solution to linear \n",
    "    regression using the normal equations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        Shape (m,n)\n",
    "        \n",
    "    y: array_like\n",
    "        Shape (m,)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    w : array_like\n",
    "        Shape (n,)\n",
    "        Parameters computed by normal equation\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 1 line of code)\n",
    "    # w = \n",
    "    ### BEGIN SOLUTION ###\n",
    "    w = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)),X.T), y)\n",
    "    ### END SOLUTION ### \n",
    "           \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_normal = normal_equation(X_train, y_train)\n",
    "print(\"w found by normal equation:\", w_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-services",
   "metadata": {},
   "source": [
    "Now let's see what the prediction is on unseen input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_orig = np.array([1650, 3])\n",
    "\n",
    "X_test_norm = (X_test_orig - mu)/sigma\n",
    "X_test = np.hstack((1, X_test_norm))\n",
    "y_pred_normal = np.dot(X_test, w_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted price of a 1650 sq-ft, 3 br house \\\n",
    "        using normal equations is is: $%.2f\" % (y_pred_normal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
